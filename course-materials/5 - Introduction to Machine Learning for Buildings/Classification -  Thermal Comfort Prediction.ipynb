{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rA-N1S8QmMZZ"
   },
   "source": [
    "# Introduction to Machine Learning for the Built Environment - Supervised Classification Models\n",
    "\n",
    "- Created by Clayton Miller - clayton@nus.edu.sg - miller.clayton@gmail.com\n",
    "\n",
    "This notebook is an introduction to the machine learning concepts of classification. We will use the ASHRAE Thermal Comfort Database II data set to predict what makes a person feel comfortable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dz08YBT3mBP4"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from google.colab import drive\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KYxnQsFkr0hM"
   },
   "outputs": [],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, roc_curve, auc, precision_recall_curve\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.feature_selection import SelectKBest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NJ37iQEToDxq"
   },
   "source": [
    "## Load the IEQ Data and find a classification objective\n",
    "\n",
    "We can constrain the data to be able to predict a certain attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e1GsDm1en4E8"
   },
   "outputs": [],
   "source": [
    "drive.mount('/content/gdrive')\n",
    "os.chdir(\"/content/gdrive/My Drive/EDX Data Science for Construction, Architecture and Engineering/4 - Operations - Statistics and Visualization/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PiIZwQVqn6U7"
   },
   "outputs": [],
   "source": [
    "ieq_data = pd.read_csv(\"ashrae_thermal_comfort_database_2.csv\", index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sp9OA0RAoCkd"
   },
   "outputs": [],
   "source": [
    "ieq_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aIhb3Q0to8zW"
   },
   "outputs": [],
   "source": [
    "ieq_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Hh2o7WBpAGG"
   },
   "outputs": [],
   "source": [
    "ieq_data[\"ThermalSensation_rounded\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-lrBZRIcrSHU"
   },
   "source": [
    "## Classification Objective -- Predict Thermal Sensation using a Random Forest Model\n",
    "\n",
    "Let's use many of the other variables to predict thermal sensation as classification objective.\n",
    "\n",
    "To do this we can use the Random Forest Classification Model. This model is a good all-purpose model that is able to ingest input features of various types. It is a form of a [decision-tree model](https://en.wikipedia.org/wiki/Decision_tree_learning).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IQyIQ6h-nf0E"
   },
   "source": [
    "## Creating Feature and Target Data Sets\n",
    "The first thing we need to do is create the the feature data set and the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G5oxp6m_noad"
   },
   "outputs": [],
   "source": [
    "ieq_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EBuLXQEVrxOC"
   },
   "outputs": [],
   "source": [
    "list(ieq_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "00Nn6JKYnkak"
   },
   "source": [
    "Let's use the following columns as input features for the classification model. These features will be used by the model to try to predict `ThermalSensation_rounded`.\n",
    "\n",
    "Several of the features are related to the building context (i.e.: `Country`, `City`), the environmental conditions (i.e.: `Air Temperature (C)`, `Relative humidity (%)`) and personal factors (i.e.: `Sex`, `Clo`, etc.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "996kd7qMrxmv"
   },
   "outputs": [],
   "source": [
    "feature_columns = [\n",
    " 'Year',\n",
    " 'Season',\n",
    " 'Climate',\n",
    " 'City',\n",
    " 'Country',\n",
    " 'Building type',\n",
    " 'Cooling startegy_building level',\n",
    " 'Sex',\n",
    " 'Clo',\n",
    " 'Met',\n",
    " 'Air temperature (C)',\n",
    " 'Relative humidity (%)',\n",
    " 'Air velocity (m/s)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TmcSagvCoXFN"
   },
   "outputs": [],
   "source": [
    "features = ieq_data[feature_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bLwBTee3oaFi"
   },
   "outputs": [],
   "source": [
    "features.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RibRtv8Qouqu"
   },
   "source": [
    "The **target** variable is the column that we want to predict - in this case, thermal sensation. We will use the \"rounded\" version to minimize the number of categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fMn8XdvdobHE"
   },
   "outputs": [],
   "source": [
    "target = ieq_data['ThermalSensation_rounded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "astDNowlpHlW"
   },
   "outputs": [],
   "source": [
    "target.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5qe5VTD_rSG-"
   },
   "source": [
    "## Create dummy variables for the categories\n",
    "\n",
    "Once again, we need to convert the categorical variables to dummy variables in order as that is the input the model expects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MuzOWUmqq-4S"
   },
   "outputs": [],
   "source": [
    "features_withdummies = pd.get_dummies(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_eAMPN05rF_w"
   },
   "outputs": [],
   "source": [
    "features_withdummies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EIxf8I4CpRIn"
   },
   "source": [
    "## Create the Train and Test Split using SK Learn\n",
    "\n",
    "Now we will create a function that will divide the data set into a random train/test combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BetJSD9LpLPz"
   },
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(features_withdummies, target, test_size=0.3, random_state=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "beEhI4-TqkkC"
   },
   "outputs": [],
   "source": [
    "features_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YVF4VJxGrZuu"
   },
   "outputs": [],
   "source": [
    "features_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kaduwQESrdAB"
   },
   "outputs": [],
   "source": [
    "features_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jYuwY5ZCVbz5"
   },
   "source": [
    "## Train the Random Forest Model and make the classification prediction\n",
    "\n",
    "We now can call the Random Forest model from sklearn that was loaded before and specify various input features (or parameters) that influence the way the model is constructed.\n",
    "\n",
    "These parameters can be optimized in order to achieve the best accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O84aOQW9qbbh"
   },
   "outputs": [],
   "source": [
    "model_rf = RandomForestClassifier(oob_score = True, max_features = 'auto', n_estimators = 100, min_samples_leaf = 2, random_state = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tbxvCmPsqexF"
   },
   "outputs": [],
   "source": [
    "model_rf.fit(features_train, target_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7RrQMYHvtFFk"
   },
   "source": [
    "## Out-of-Bag (OOB) Error Calculation\n",
    "\n",
    "OOB is a metric to measure the accuracy of the classification to predict the right class. The fact that we have six classes to predict makes this classification a bit of challenge.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2m1edD2_qhqF"
   },
   "outputs": [],
   "source": [
    "mean_model_accuracy = model_rf.oob_score_\n",
    "\n",
    "print(\"Model accuracy: \"+str(mean_model_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sxJfBD9ZtcT9"
   },
   "source": [
    "The model is accurate about half the time in predicting if someone is comfortable. That seems low, but let's find where the baseline is.\n",
    "\n",
    "## Create a Baseline Model to compare the accuracy of the model\n",
    "\n",
    "Sci-kit learn allows you to create a baseline which is the accuracy in just random guessing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PNG1CIFCtS7h"
   },
   "outputs": [],
   "source": [
    "#Dummy Classifier model to get a baseline\n",
    "baseline_rf = DummyClassifier(strategy='stratified',random_state=0)\n",
    "baseline_rf.fit(features_train, target_train)\n",
    "#DummyClassifier(constant=None, random_state=1, strategy='most_frequent')\n",
    "baseline_model_accuracy = baseline_rf.score(features_test, target_test)\n",
    "print(\"Model accuracy: \"+str(baseline_model_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6w_XLFfPyvg3"
   },
   "source": [
    "The baseline model is only 28%, therefore our model is almost twice the accuracy at predicting the right value\n",
    "\n",
    "## Classification Report\n",
    "\n",
    "Classification is often evaluated by more than just accuracy -- there are several other metrics that are calculated to understand the success to classification. We can report that outlines the `precision`, `recall`, `f1-score`, and `support` metrics for each of the classes being predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_x6w5nBxtk4m"
   },
   "outputs": [],
   "source": [
    "y_pred = model_rf.predict(features_test)\n",
    "y_true = np.array(target_test)\n",
    "categories = np.array(target.sort_values().unique())\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P0k8zD-My6uj"
   },
   "source": [
    "## Feature Importance\n",
    "\n",
    "With Random Forest models, there is the built-in capability to calculate the **Feature Importance**. This value is calculated based on which features most contribute to accurate predictions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OZPVLfEZy0CU"
   },
   "outputs": [],
   "source": [
    "importances = model_rf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in model_rf.estimators_], axis=0)\n",
    "indices = np.argsort(importances)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-mmtYYR8zApk"
   },
   "outputs": [],
   "source": [
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(features_withdummies.shape[1]):\n",
    "    print(\"%d. feature %s (%f)\" % (f + 1, features_withdummies.columns[indices[f]], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2VK4nE-2zb44"
   },
   "source": [
    "According to the feature importance analysis, it seems that the conventional environmental metrics are the best predictors of comfort followed by the personal factors\n",
    "\n",
    "## Plot Feature Importance\n",
    "\n",
    "We can also plot the feature importance in a line chart of the top features to get a better visual sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nTVUt2PuzB0J"
   },
   "outputs": [],
   "source": [
    "# Plot the feature importances of the forest\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.title(\"Feature Importances\")\n",
    "plt.barh(range(15), importances[indices][:15], align=\"center\")\n",
    "plt.yticks(range(15), features_withdummies.columns[indices][:15])#\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout(pad=0.4)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bKcCTN4tXfDD"
   },
   "source": [
    "## Classification Confusion Matrix Visualization\n",
    "\n",
    "A confusion matrix is a visualization that helps a user understand which classes are being misclassified \n",
    "\n",
    "In this case we will look at absolute numbers of misclassifications and a normalized version of misclassification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eA-kcPyC0ket"
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, categories, title='Confusion matrix', cmap='Reds'):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(categories))\n",
    "    plt.xticks(tick_marks,categories, rotation=90)\n",
    "    plt.yticks(tick_marks,categories)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BLealUC3zJop"
   },
   "outputs": [],
   "source": [
    "# Compute confusion matrix: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "sns.set(font_scale=1.4)\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "print('Confusion matrix, without normalization')\n",
    "print(cm)\n",
    "plt.figure(figsize=(12,10))\n",
    "plot_confusion_matrix(cm, categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fvNg89KW0du6"
   },
   "outputs": [],
   "source": [
    "# Normalize the confusion matrix by row (i.e by the number of samples\n",
    "# in each class)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print('Normalized confusion matrix')\n",
    "print(cm_normalized)\n",
    "plt.figure(figsize=(12,10))\n",
    "plot_confusion_matrix(cm_normalized, categories, title='Normalized Classification Error Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xxNa1kxv0tuY"
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Classification -  Thermal Comfort Prediction.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
